arrivErr_st  = arrivErr_st,
#lnErrSD      = log(mean(errSD_s)),
lnErrSD_s    = log(errSD_s),
logitCor_ss  = logit(cor_ss,lb=-1,ub=1),
lnqE_sg      = log(qE_sg),
lnqI_s       = log(qI_s),
lnDisp_tg    = lnDisp_tg )
if(!is.null(arrivSD))
pars$lnArrivSD_s <- rep(log(arrivSD),nS)
qEmap_sg <- matrix( data=1:(nS*nG), nrow=nS, ncol=nG )
qEmap_sg[ ,1] <- NA
qEmap_sg[ ,2] <- ctrl$map$qFishWheel_s
corMap_ss <- matrix( data=1:(nS*nS), nrow=nS, ncol=nS )
# Always fix diagonal
diag(corMap_ss) <- NA
# Optional - define map for lower triangle
# Let's fix the lower triangle (except diag) at a single value
for( s in 2:nS )
{
if( ctrl$map$corType=="uncor" )
corMap_ss[s,1:(s-1)] <- NA
else if( ctrl$map$corType=="single" )
corMap_ss[s,1:(s-1)] <- nS^2+1
}
# Mirror upper & lower triangle
corMap_ss <- mirrorMatrix(corMap_ss)
dispMap <- NA*lnDisp_tg
mapArrivErr_st <- matrix( data=1:(nS*(nT-1)), nrow=nS, ncol=nT-1 )
mapArrivErr_st[ ,which(apply(n_sdtg,3,sum,na.rm=TRUE)==0)-1] <- NA
map <- list( lnArrivMu_s = as.factor(ctrl$map$arrivMu_s),
lnArrivSD_s = as.factor(ctrl$map$arrivSD_s),
arrivErr_st = as.factor(mapArrivErr_st),
lnErrSD_s   = as.factor(ctrl$map$errSD_s),
logitCor_ss = as.factor(corMap_ss),
lnqE_sg     = as.factor(qEmap_sg),
lnqI_s      = as.factor(NA*ctrl$map$qI_s),
lnDisp_tg   = as.factor(dispMap) )
# Load the DLL
if("yukonChinookRunRecon" %in% names(getLoadedDLLs()))
dyn.unload(dynlib("yukonChinookRunRecon"))          # unlink the C++ code if already linked
# Compile the model
compile("yukonChinookRunRecon.cpp", flags = "-g")
# Compile the model
compile(here("analysis/R/run-reconstructions/yukonChinookRunRecon.cpp")), flags = "-g")
# Compile the model
compile(here("analysis/R/run-reconstructions/yukonChinookRunRecon.cpp"), flags = "-g")
# Load the DLL
dyn.load(dynlib("yukonChinookRunRecon"))          # Dynamically link the C++ code
# Load the DLL
dyn.load(dynlib(here("analysis/R/run-reconstructions/yukonChinookRunRecon")))          # Dynamically link the C++ code
# Build objective function
obj <- MakeADFun( data       = data,
parameters = pars,
map        = map,
DLL        = "yukonChinookRunRecon",
random     = NULL )
# Set bounds
low <- obj$par*0-Inf
upp <- obj$par*0+Inf
# Optimization controlsarrivSD
optCtrl <- list(  eval.max = ctrl$maxFunEval,
iter.max = ctrl$maxIterations )
# Optimize
#sink("sink.txt")
opt <- try( nlminb( start     = obj$par,
objective = obj$fn,
gradient  = obj$gr,
lower     = low,
upper     = upp,
control   = optCtrl ) )
rptFE <- obj$report()
if( ctrl$randEffects )
{
# Build objective function
obj <- MakeADFun( data       = data,
parameters = rptFE[names(pars)],
map        = map,
DLL        = "yukonChinookRunRecon",
random     = "arrivErr_st" )
# Optimize
sink("sink.txt")
opt <- try( nlminb( start     = obj$par,
objective = obj$fn,
gradient  = obj$gr,
lower     = low,
upper     = upp,
control   = optCtrl ) )
sink()
}
sdrep <- NULL
errGrad <- NULL
if( mode(opt)=="character" )
{
rpt <- obj$report()
rpt$opt$convergence <- 1
}
else
{
# Retrieve optimized parameters and gradients
par <- data.frame( par  = names(opt$par),
val  = opt$par,
grad = as.numeric(obj$gr()) )
# Calculate standard errors via delta method
sink("sink.txt")
sdobj <- sdreport( obj )
sdrpt <- summary( sdobj )
sink()
if( mode(sdrpt)!="character" )
{
colnames(sdrpt) <- c("val","se")
sdrpt <- as.data.frame(sdrpt) %>%
mutate( par = rownames(sdrpt),
lCI = val - qnorm(.95)*se,
uCI = val + qnorm(.95)*se ) %>%
dplyr::select( par, val, se, lCI, uCI )
}
# Build report object
rpt <- obj$report()
rpt$opt    <- opt
rpt$years  <- years
rpt$gears  <- gears
rpt$stocks <- stocks
rpt$par    <- par
rpt$sdrpt  <- sdrpt
#rpt$errGrad_st <- errGrad_st
nObs <- sum(!is.na(data$n_sdtg[1, , , ])) +
sum(!is.na(data$E_dtg)) +
length(data$I_t)
nPar <- length(opt$par)
nll  <- opt$objective
aic  <- 2*nPar + 2*nll + 2*nPar*(nPar+1)/(nObs-nPar-1)
rpt$aic <- aic
#  library(tmbstan)
#  options(mc.cores = 3)
#  mcinit <- list()
#  for( i in 1:3 )
#    mcinit[[i]] <- rnorm(n=length(obj$par),mean=obj$par,sd=1e-5)
#
#  fit <- tmbstan( obj = obj,
#                  chains = 3,
#                  iter = 1e3,
#                  init = mcinit )
#  rpt$fit <- fit
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
}
folder
saveRun=TRUE
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
source(here("analysis/R/run-reconstructions/plot.R"))    # Plotting functions
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
folder
plotFitI(rpt=rpt,folder=folder)
plotTotalRunSize(rpt=rpt,folder=folder)
plotRunSize(rpt=rpt,folder=folder)
plotArrival(rpt=rpt,folder=folder)
plotArrivalByYear(rpt=rpt,folder=folder)
controlTable  <- .readParFile( "estControlFile.txt" )
controlTable
plotArrivalByYear <- function( rpt, folder="." )
{
controlTable  <- .readParFile( ctlFile )
ctrl <- .createList( controlTable )
stocks <- ctrl$stks
cols <- brewer.pal(rpt$nS,"Set1")
d <- rpt$day_d
i <- 1
for( t in 1:rpt$nT )
{
if( t %in% c(1,17) )
{
pdf( file=paste(folder,"/arrivalTimingByYear",i,".pdf",sep=""), height=7, width=9 )
par( mfrow=c(4,4), mar=c(2,2,0.5,0.5), oma=c(3,3,0,0) )
}
N_ds <- rpt$N_dst[ , ,t]*1e-3
maxy <- max(N_ds)
plot( x=range(d), y=c(0,1.15*maxy), type="n", xlab="",
ylab="", las=1 )
plotbg()
box()
for( s in 1:rpt$nS )
lines( x=d, y=N_ds[ ,s], col=cols[s], lwd=1.5 )
legend( x="topleft", bty="n", legend=rpt$years[t] )
legend( x="topright", bty="n", col=cols, lwd=1.5, legend=stocks, cex=0.6 )
if( t %in% c(rpt$nT,rpt$nT/2) )
{
mtext( side=2, text="Daily border passage (1000s)", outer=TRUE, line=1, cex=1.3 )
mtext( side=1, text="Julian day", outer=TRUE, line=1, cex=1.3 )
}
if( t %in% c(16,rpt$nT) )
{
dev.off()
i <- i + 1
}
}
}
plotArrival(rpt=rpt,folder=folder)
plotArrivalByYear(rpt=rpt,folder=folder)
plotCompResid(rpt=rpt,folder=folder)
plotCompFits(rpt=rpt,folder=folder)
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
# Initialize
source(here("analysis/R/run-reconstructions/initRR.R"))
# -- aggregate run-size counts by day, N_gyd --
counts <- read.csv(here("analysis/data/raw/borderCounts.csv"))
# -- GSI sub-stock sampling by day, n_sgyd --
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv")) %>%
rename( sample_num=fish )
stockID <- read.csv(here("analysis/data/raw/stockIDs.csv")) %>% arrange(plotOrder)
stockID <- read.csv(here("analysis/data/raw/stockIDs.csv")) %>% arrange(plotOrder)
# External run size indices for fish wheel years only (<2005)
borderPass <- read.csv(here("analysis/data/raw/border-passage.csv"))
source(here("analysis/R/run-reconstructions/procData.R"))
processData()
rpt <- fitRR()
dyn.unload(dynlib(here("analysis/R/run-reconstructions/yukonChinookRunRecon")))          # unlink the C++ code if already linked
source(here("analysis/R/run-reconstructions/initRR.R"))
rpt <- fitRR()
# process and save time-series of spawner abundance
cdn_harvest <- read.csv(here("analysis/data/raw/YkCk_Harvest_CA_Data.csv")) %>%
filter(Type == "CA_Mainstem",
Year > 1984) %>%
select(Year, Estimate)
border_passage <- rpt[["runSize_t"]]
cdn_er <- cdn_harvest$Estimate/(cdn_harvest$Estimate+border_passage)
CU_border_passage <- exp(rpt$lnRunSize_st)*1e-3
CU_spwn <- CU_border_passage * (1-cdn_er)
colnames(CU_spwn) <- seq(1985,2023)
rownames(CU_spwn) <- c("NorthernYukonR.andtribs.","Whiteandtribs.","Pelly","Stewart","Nordenskiold","YukonR.Teslinheadwaters","MiddleYukonR.andtribs.","UpperYukonR.")
CU_spwn_df <- as.data.frame(CU_spwn)
CU_spwn_df$CU <- rownames(CU_spwn)
CU_spawn_long <- CU_spwn_df %>%
pivot_longer(!CU, names_to = 'Year', values_to = 'spawn')
Rse <- filter(rpt$sdrpt,par=="runSize_st")
library(tidyverse)
CU_spawn_long <- CU_spwn_df %>%
pivot_longer(!CU, names_to = 'Year', values_to = 'spawn')
Rse <- filter(rpt$sdrpt,par=="runSize_st")
CU_spawn_long$lwr <- Rse$lCI*1e-3
CU_spawn_long$upr <- Rse$uCI*1e-3
CU_spawn_long$se <- Rse$se*1e-3
mssr_spwn <- CU_spawn_long %>%
mutate(year = as.numeric(Year),
cv = se/spawn,
stock = CU,
mean = as.numeric(spawn)*1000,
obs = 1) %>%
select(stock, year, mean, se, cv, obs)
write.csv(mssr_spwn, here("analysis/data/raw/esc-data.csv"),row.names = F)
mssr_spwn
# calculate CU specific harvest based on reconstructed spawner abundance and aggregate exploitation rate
er <- read.csv(here("analysis/data/raw/rr-table.csv"))
cdn_er <- er %>%
filter(stock == "Canadian",
Year > 1984) %>%
mutate(er = Harvest.rate..../100)
cdn_er
agg_er <- as.vector(cdn_er$er)
agg_er
rep(agg_er,2)
agg_er <- rep(as.vector(cdn_er$er),8)
agg_er
harv <- cbind(mssr_spwn, agg_er)
harv
harv$harv <- (harv$spawn/(1-harv$agg_er))*harv$agg_er
harv$harv <- (harv$mean/(1-harv$agg_er))*harv$agg_er
harv
er
# calculate CU specific harvest based on reconstructed spawner abundance and aggregate exploitation rate
er <- read.csv(here("analysis/data/raw/rr-table.csv"))
cdn_er <- er %>%
filter(stock == "Canadian",
Year > 1984) %>%
mutate(er = Harvest.rate..../100,
cv = Harvest.CV)
cdn_er
er <- read.csv(here("analysis/data/raw/rr-table.csv"))
cdn_er <- er %>%
filter(stock == "Canadian",
Year > 1984) %>%
mutate(er = Harvest.rate..../100,
cv = Harvest.CV)
agg_er <- rep(as.vector(cdn_er$er),8)
agg_cv <- rep(as.vector(cdn_er$cv),8)
harv <- cbind(mssr_spwn, agg_eragg_cv)
harv <- cbind(mssr_spwn, agg_er,agg_cv)
harv$harv <- (harv$mean/(1-harv$agg_er))*harv$agg_er
harv
harvest <- harv[,c(1,2,9,8)]
harvest
colnames(harvest) <- c("population", "year","harv","cv")
harvest
write.csv(harvest,here("analysis/data/raw/harvest-data.csv"))
write.csv(harvest,here("analysis/data/raw/harvest-data.csv"))
x <- c("asfef", "qwerty", "yuiop[", "b", "stuff.blah.yech")
substr(x, 2, 5)
library(tidyverse)
library(here)
#helper funs-----------------------------------------------------------------------------
#needed since using native pipe (i.e. referencing '.' doesn't work)
my_replace <- function(x){
return(replace(
x = x,
list = is.na(x),
values = 0))
}
as <- read.csv(here("analysis/data/raw/border-asl.csv")) |>
select(Sample.Year, julian, Gear, Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
rename(Year = Sample.Year) |>
group_by(Year, Sex, Gear, Age) |>
summarise(n = n()) |>
arrange(as.numeric(Age)) |>
pivot_wider(names_from = Age,
values_from = n) |>
my_replace()|>
arrange(Year, Sex) |>
as.data.frame()
View(as)
as <- read.csv(here("analysis/data/raw/border-asl.csv")) |>
select(Sample.Year, julian, Gear, Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
rename(Year = Sample.Year)
#read in and wrangle tables--------------------------------------------------------------
as <- read.csv(here("analysis/data/raw/border-asl.csv")) |>
select(Sample.Year, julian, Gear, FIsh.Number,Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
rename(Year = Sample.Year)
#read in and wrangle tables--------------------------------------------------------------
as <- read.csv(here("analysis/data/raw/border-asl.csv")) |>
select(Sample.Year, julian, Gear, Fish.Number,Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
rename(Year = Sample.Year)
#read in and wrangle tables--------------------------------------------------------------
as <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
select(Sample.Year, julian, Gear, Fish.Number,Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
rename(Year = Sample.Year)
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(Year = sampleYear) |>
filter(species == "Chiook")
#read in and wrangle tables--------------------------------------------------------------
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(Year = sampleYear,
fish = Genetic.Sample.Number) |>
filter(species == "Chinook") |>
mutate(age = ageFresh + ageSalt +1)
View(asl)
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(Year = sampleYear,
fish = Genetic.Sample.Number) |>
filter(species == "Chinook") |>
mutate(age = ageFresh + ageSalt +1)
select(Year, julian, Gear, fish ,SexID, length, age)
#read in and wrangle tables--------------------------------------------------------------
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(Year = sampleYear,
fish = Genetic.Sample.Number) |>
filter(species == "Chinook") |>
mutate(age = ageFresh + ageSalt +1) |>
select(Year, julian, Gear, fish ,SexID, length, age)
#read in and wrangle tables--------------------------------------------------------------
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(Year = sampleYear,
fish = Genetic.Sample.Number) |>
filter(species == "Chinook") |>
mutate(age = ageFresh + ageSalt +1) |>
select(Year, julian, fish ,SexID, length, age)
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(Year = sampleYear,
fish = Genetic.Sample.Number) |>
filter(species == "Chinook") |>
mutate(age = ageFresh + ageSalt +1) |>
select(Year, julian, fish, sexID, length, age)
#read in gsi and merge with asl--------------------------------------------------------------
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv")) %>%
as <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
select(Sample.Year, julian, Gear, Fish.Number,Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
as <- read.csv(here("analysis/data/raw/border-asl.csv")) |>
select(Sample.Year, julian, Gear, Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
rename(Year = Sample.Year) |>
group_by(Year, Sex, Gear, Age) |>
summarise(n = n()) |>
arrange(as.numeric(Age)) |>
pivot_wider(names_from = Age,
values_from = n) |>
my_replace()|>
arrange(Year, Sex) |>
as.data.frame()
#read in gsi and merge with asl--------------------------------------------------------------
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv")) %>%
as <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
select(Sample.Year, julian, Gear, Fish.Number,Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
as <- read.csv(here("analysis/data/raw/border-asl.csv")) |>
select(Sample.Year, julian, Gear, Sex, Fresh.Water.Age, Salt.Water.Age) |>
filter(!is.na(Fresh.Water.Age) & !is.na(Salt.Water.Age)) |>
mutate(Age = paste0(Fresh.Water.Age, ".", Salt.Water.Age)) |>
rename(Year = Sample.Year) |>
group_by(Year, Sex, Gear, Age) |>
summarise(n = n()) |>
arrange(as.numeric(Age)) |>
pivot_wider(names_from = Age,
values_from = n) |>
my_replace()|>
arrange(Year, Sex) |>
as.data.frame()
#read in gsi and merge with asl--------------------------------------------------------------
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv"))
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(year = sampleYear,
fish = Genetic.Sample.Number) |>
filter(species == "Chinook") |>
mutate(age = ageFresh + ageSalt +1) |>
select(Year, julian, fish, sexID, length, age)
#read in and wrangle asl--------------------------------------------------------------
asl <- read.csv(here("analysis/data/raw/ASL_Output_Chinook_Eagle_2005-2019.csv")) |>
rename(year = sampleYear,
fish = Genetic.Sample.Number) |>
filter(species == "Chinook") |>
mutate(age = ageFresh + ageSalt +1) |>
select(year, julian, fish, sexID, length, age)
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv")) |>
filter(year %in% c(2005:2019),
gear == "Test Fishery")
#read in gsi and merge with asl--------------------------------------------------------------
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv")) |>
filter(year %in% c(2005:2019),
gear == "Test Fishery") |>
left_join(., asl, by = c("year", "julian", "fish")) |>
group_by(year, julian, fish) |>
filter(prob == max(prob)) |>
arrange(year, fish) |>
as.data.frame()
#read in gsi and merge with asl--------------------------------------------------------------
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv")) |>
filter(year %in% c(2005:2019),
gear == "Test Fishery") |>
left_join( asl, by = c("year", "julian", "fish")) |>
group_by(year, julian, fish) |>
filter(prob == max(prob)) |>
arrange(year, fish) |>
as.data.frame()
View(gsi)
age_comps <- gsi |>
group_by(Year, CU, age) |>
summarise(n = n()) |>
arrange(as.numeric(age))
age_comps <- gsi |>
group_by(year, CU, age) |>
summarise(n = n()) |>
arrange(as.numeric(age))
View(age_comps)
age_comps <- gsi |>
group_by(year, CU, age) |>
summarise(n = n()) |>
arrange(as.numeric(age)) |>
pivot_wider(names_from = Age,
values_from = n) |>
my_replace()|>
arrange(year, CU) |>
as.data.frame()
age_comps <- gsi |>
group_by(year, CU, age) |>
summarise(n = n()) |>
arrange(as.numeric(age)) |>
pivot_wider(names_from = age,
values_from = n) |>
my_replace()|>
arrange(year, CU) |>
as.data.frame()
age_comps <- gsi |>
drop_na(age) |>
group_by(year, CU, age) |>
summarise(n = n()) |>
arrange(as.numeric(age)) |>
pivot_wider(names_from = age,
values_from = n) |>
my_replace()|>
arrange(year, CU) |>
as.data.frame()
pop_age_comp_2008_2019 <- readRDS("C:/Users/CONNORSB/Documents/Github/yukon-chinook-diversity - 2022-update/01_inputs/data/pop_age_comp_2008_2019.rds")
pop_age_comp_2008_2019

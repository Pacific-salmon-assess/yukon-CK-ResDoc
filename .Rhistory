upper     = upp,
control   = optCtrl ) )
sink()
}
#hes <- round(solve(obj$he(opt$par)),10)
#samps <- mvtnorm::rmvnorm(7, opt$par, hes)
sdrep <- NULL
errGrad <- NULL
if( mode(opt)=="character" )
{
rpt <- obj$report()
rpt$opt$convergence <- 1
}
else
{
# Retrieve optimized parameters and gradients
par <- data.frame( par  = names(opt$par),
val  = opt$par,
grad = as.numeric(obj$gr()) )
# Calculate standard errors via delta method
sink("sink.txt")
sdobj <- sdreport( obj )
sdrpt <- summary( sdobj )
sink()
if( mode(sdrpt)!="character" )
{
colnames(sdrpt) <- c("val","se")
sdrpt <- as.data.frame(sdrpt) %>%
mutate( par = rownames(sdrpt),
lCI = val - qnorm(.95)*se,
uCI = val + qnorm(.95)*se ) %>%
dplyr::select( par, val, se, lCI, uCI )
}
# Build report object
rpt <- obj$report()
rpt$opt    <- opt
rpt$years  <- years
rpt$gears  <- gears
rpt$stocks <- stocks
rpt$par    <- par
rpt$sdrpt  <- sdrpt
#rpt$errGrad_st <- errGrad_st
nObs <- sum(!is.na(data$n_sdtg[1, , , ])) +
sum(!is.na(data$E_dtg)) +
length(data$I_t)
nPar <- length(opt$par)
nll  <- opt$objective
aic  <- 2*nPar + 2*nll + 2*nPar*(nPar+1)/(nObs-nPar-1)
rpt$aic <- aic
#  library(tmbstan)
#  options(mc.cores = 3)
#  mcinit <- list()
#  for( i in 1:3 )
#    mcinit[[i]] <- rnorm(n=length(obj$par),mean=obj$par,sd=1e-5)
#
#  fit <- tmbstan( obj = obj,
#                  chains = 3,
#                  iter = 1e3,
#                  init = mcinit )
#  rpt$fit <- fit
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
}
rpt
}
source("fitRR.R")
source(here("analysis/R/run-reconstructions/fitRR.R"))
rpt <- fitRR()
# Initialize
source("analysis/R/run-reconstructions/initRR.R")
# Read in control file
controlTable  <- .readParFile( ctlFile )
.readParFile
controlTable  <- .readParFile( analysis/R/run-reconstructions/ctlFile )
ctlFile="analysis/R/run-reconstructions/estControlFile.txt"
# Read in control file
controlTable  <- .readParFile( ctlFile )
ctlFile="analysis/R/run-reconstructions/fittedMod/estControlFile.txt"
# Read in control file
controlTable  <- .readParFile( ctlFile )
# Create control list
ctrl <- .createList( controlTable )
init  <- ctrl$inits
# Load abundance indices and stock composition data
load(here("analysis/data/chinookYkData.Rdata"))
# Dimensions
years  <- ctrl$initYear:ctrl$lastYear
days   <- chinookYkData$days
gears  <- chinookYkData$gears
stocks <- ctrl$stocks
nT     <- length(years)
nD     <- length(days)
nG     <- length(gears)
nS     <- length(stocks)
# Create directory for saving plots and report
suppressWarnings(dir.create(folder))
folder="analysis/R/run-reconstructions/fittedMod"
# Create directory for saving plots and report
suppressWarnings(dir.create(folder))
# Observed numbers by stock, day, year and gear
n_sdtg <- chinookYkData$n_sdtg[ , ,as.character(years), ]
# Abundance indices by day, year and gear
E_dtg  <- chinookYkData$E_dtg[ ,as.character(years), ]
# Mark-recapture run size indices for fish wheel years only (<2005)
borderPass <- chinookYkData$borderPass %>%
filter( year %in% years )
I_t <- borderPass$mean
CV_t <- borderPass$cv
I_t[years>=2005] <- NA
CV_t[years>=2005] <- NA
# Set NAs before first obs and after last obs to 0
for( t in 1:nT )
{
for( g in 1:nG )
{
E <- E_dtg[ ,t,g]
if( sum(!is.na(E)) > 0 )
{
E_dtg[is.na(E),t,g] <- 0
}
}
}
# Create TMB data object
data <- list( n_sdtg    = n_sdtg,
E_dtg     = E_dtg,
I_t       = I_t,
day_d     = days,
CV_t      = CV_t,
runRW     = runRW,    # Run size random walk switch (0=off, 1=on)
runSD     = 1 )       # Run size random walk std dev
runRW=1
# Set NAs before first obs and after last obs to 0
for( t in 1:nT )
{
for( g in 1:nG )
{
E <- E_dtg[ ,t,g]
if( sum(!is.na(E)) > 0 )
{
E_dtg[is.na(E),t,g] <- 0
}
}
}
# Create TMB data object
data <- list( n_sdtg    = n_sdtg,
E_dtg     = E_dtg,
I_t       = I_t,
day_d     = days,
CV_t      = CV_t,
runRW     = runRW,    # Run size random walk switch (0=off, 1=on)
runSD     = 1 )       # Run size random walk std dev
# Simulated data
if( !is.null(simData) )
data <- simData
# Initial conditions
runSize_st <- matrix( data=init$runSize_s, nrow=nS, ncol=nT )
initMu_s   <- init$arrivMu_s
sigma_s    <- init$arrivSD_s
arrivErr_st <- matrix( data=0, nrow=nS, ncol=nT-1 )
qE_sg      <- matrix( data=1, nrow=nS, ncol=nG )
qE_sg[ ,2] <- 0.05
qI_s       <- rep(1,nS)
errSD_s    <- init$errSD_s
obsErrSD_g <- rep(0.1,nG)
cor_ss     <- matrix( data=0, nrow=nS, ncol=nS )
diag(cor_ss) <- 1 # Correlation matrix must have 1 on diagonal
lnDisp_tg  <- matrix( data=log(1e-4), nrow=nT, ncol=nG )
#lnDisp_tg[4,2]  <- log(1)
#lnDisp_tg[22,2] <- log(0.5)
#lnDisp_tg[23,2] <- log(0.5)
lnDisp_tg[ ,2] <- log(0.02)
lnDisp_tg[17,2] <- log(2)
# Create TMB parameter object
pars <- list( lnRunSize_st = log(runSize_st),
lnArrivMu_s  = log(initMu_s),
#lnArrivSD    = log(mean(sigma_s)),
lnArrivSD_s  = log(sigma_s),
arrivErr_st  = arrivErr_st,
#lnErrSD      = log(mean(errSD_s)),
lnErrSD_s    = log(errSD_s),
logitCor_ss  = logit(cor_ss,lb=-1,ub=1),
lnqE_sg      = log(qE_sg),
lnqI_s       = log(qI_s),
lnDisp_tg    = lnDisp_tg )
if(!is.null(arrivSD))
pars$lnArrivSD_s <- rep(log(arrivSD),nS)
qEmap_sg <- matrix( data=1:(nS*nG), nrow=nS, ncol=nG )
qEmap_sg[ ,1] <- NA
qEmap_sg[ ,2] <- ctrl$map$qFishWheel_s
arrivSD=NULL
# Create TMB parameter object
pars <- list( lnRunSize_st = log(runSize_st),
lnArrivMu_s  = log(initMu_s),
#lnArrivSD    = log(mean(sigma_s)),
lnArrivSD_s  = log(sigma_s),
arrivErr_st  = arrivErr_st,
#lnErrSD      = log(mean(errSD_s)),
lnErrSD_s    = log(errSD_s),
logitCor_ss  = logit(cor_ss,lb=-1,ub=1),
lnqE_sg      = log(qE_sg),
lnqI_s       = log(qI_s),
lnDisp_tg    = lnDisp_tg )
if(!is.null(arrivSD))
pars$lnArrivSD_s <- rep(log(arrivSD),nS)
qEmap_sg <- matrix( data=1:(nS*nG), nrow=nS, ncol=nG )
qEmap_sg[ ,1] <- NA
qEmap_sg[ ,2] <- ctrl$map$qFishWheel_s
corMap_ss <- matrix( data=1:(nS*nS), nrow=nS, ncol=nS )
# Always fix diagonal
diag(corMap_ss) <- NA
# Optional - define map for lower triangle
# Let's fix the lower triangle (except diag) at a single value
for( s in 2:nS )
{
if( ctrl$map$corType=="uncor" )
corMap_ss[s,1:(s-1)] <- NA
else if( ctrl$map$corType=="single" )
corMap_ss[s,1:(s-1)] <- nS^2+1
}
# Mirror upper & lower triangle
corMap_ss <- mirrorMatrix(corMap_ss)
dispMap <- NA*lnDisp_tg
mapArrivErr_st <- matrix( data=1:(nS*(nT-1)), nrow=nS, ncol=nT-1 )
mapArrivErr_st[ ,which(apply(n_sdtg,3,sum,na.rm=TRUE)==0)-1] <- NA
map <- list( lnArrivMu_s = as.factor(ctrl$map$arrivMu_s),
lnArrivSD_s = as.factor(ctrl$map$arrivSD_s),
arrivErr_st = as.factor(mapArrivErr_st),
lnErrSD_s   = as.factor(ctrl$map$errSD_s),
logitCor_ss = as.factor(corMap_ss),
lnqE_sg     = as.factor(qEmap_sg),
lnqI_s      = as.factor(NA*ctrl$map$qI_s),
lnDisp_tg   = as.factor(dispMap) )
# Load the DLL
if("yukonChinookRunRecon" %in% names(getLoadedDLLs()))
dyn.unload(dynlib("yukonChinookRunRecon"))          # unlink the C++ code if already linked
# Compile the model
compile("yukonChinookRunRecon.cpp", flags = "-g")
# Compile the model
compile(here("analysis/R/run-reconstructions/yukonChinookRunRecon.cpp")), flags = "-g")
# Compile the model
compile(here("analysis/R/run-reconstructions/yukonChinookRunRecon.cpp"), flags = "-g")
# Load the DLL
dyn.load(dynlib("yukonChinookRunRecon"))          # Dynamically link the C++ code
# Load the DLL
dyn.load(dynlib(here("analysis/R/run-reconstructions/yukonChinookRunRecon")))          # Dynamically link the C++ code
# Build objective function
obj <- MakeADFun( data       = data,
parameters = pars,
map        = map,
DLL        = "yukonChinookRunRecon",
random     = NULL )
# Set bounds
low <- obj$par*0-Inf
upp <- obj$par*0+Inf
# Optimization controlsarrivSD
optCtrl <- list(  eval.max = ctrl$maxFunEval,
iter.max = ctrl$maxIterations )
# Optimize
#sink("sink.txt")
opt <- try( nlminb( start     = obj$par,
objective = obj$fn,
gradient  = obj$gr,
lower     = low,
upper     = upp,
control   = optCtrl ) )
rptFE <- obj$report()
if( ctrl$randEffects )
{
# Build objective function
obj <- MakeADFun( data       = data,
parameters = rptFE[names(pars)],
map        = map,
DLL        = "yukonChinookRunRecon",
random     = "arrivErr_st" )
# Optimize
sink("sink.txt")
opt <- try( nlminb( start     = obj$par,
objective = obj$fn,
gradient  = obj$gr,
lower     = low,
upper     = upp,
control   = optCtrl ) )
sink()
}
sdrep <- NULL
errGrad <- NULL
if( mode(opt)=="character" )
{
rpt <- obj$report()
rpt$opt$convergence <- 1
}
else
{
# Retrieve optimized parameters and gradients
par <- data.frame( par  = names(opt$par),
val  = opt$par,
grad = as.numeric(obj$gr()) )
# Calculate standard errors via delta method
sink("sink.txt")
sdobj <- sdreport( obj )
sdrpt <- summary( sdobj )
sink()
if( mode(sdrpt)!="character" )
{
colnames(sdrpt) <- c("val","se")
sdrpt <- as.data.frame(sdrpt) %>%
mutate( par = rownames(sdrpt),
lCI = val - qnorm(.95)*se,
uCI = val + qnorm(.95)*se ) %>%
dplyr::select( par, val, se, lCI, uCI )
}
# Build report object
rpt <- obj$report()
rpt$opt    <- opt
rpt$years  <- years
rpt$gears  <- gears
rpt$stocks <- stocks
rpt$par    <- par
rpt$sdrpt  <- sdrpt
#rpt$errGrad_st <- errGrad_st
nObs <- sum(!is.na(data$n_sdtg[1, , , ])) +
sum(!is.na(data$E_dtg)) +
length(data$I_t)
nPar <- length(opt$par)
nll  <- opt$objective
aic  <- 2*nPar + 2*nll + 2*nPar*(nPar+1)/(nObs-nPar-1)
rpt$aic <- aic
#  library(tmbstan)
#  options(mc.cores = 3)
#  mcinit <- list()
#  for( i in 1:3 )
#    mcinit[[i]] <- rnorm(n=length(obj$par),mean=obj$par,sd=1e-5)
#
#  fit <- tmbstan( obj = obj,
#                  chains = 3,
#                  iter = 1e3,
#                  init = mcinit )
#  rpt$fit <- fit
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
}
folder
saveRun=TRUE
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
source(here("analysis/R/run-reconstructions/plot.R"))    # Plotting functions
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
folder
plotFitI(rpt=rpt,folder=folder)
plotTotalRunSize(rpt=rpt,folder=folder)
plotRunSize(rpt=rpt,folder=folder)
plotArrival(rpt=rpt,folder=folder)
plotArrivalByYear(rpt=rpt,folder=folder)
controlTable  <- .readParFile( "estControlFile.txt" )
controlTable
plotArrivalByYear <- function( rpt, folder="." )
{
controlTable  <- .readParFile( ctlFile )
ctrl <- .createList( controlTable )
stocks <- ctrl$stks
cols <- brewer.pal(rpt$nS,"Set1")
d <- rpt$day_d
i <- 1
for( t in 1:rpt$nT )
{
if( t %in% c(1,17) )
{
pdf( file=paste(folder,"/arrivalTimingByYear",i,".pdf",sep=""), height=7, width=9 )
par( mfrow=c(4,4), mar=c(2,2,0.5,0.5), oma=c(3,3,0,0) )
}
N_ds <- rpt$N_dst[ , ,t]*1e-3
maxy <- max(N_ds)
plot( x=range(d), y=c(0,1.15*maxy), type="n", xlab="",
ylab="", las=1 )
plotbg()
box()
for( s in 1:rpt$nS )
lines( x=d, y=N_ds[ ,s], col=cols[s], lwd=1.5 )
legend( x="topleft", bty="n", legend=rpt$years[t] )
legend( x="topright", bty="n", col=cols, lwd=1.5, legend=stocks, cex=0.6 )
if( t %in% c(rpt$nT,rpt$nT/2) )
{
mtext( side=2, text="Daily border passage (1000s)", outer=TRUE, line=1, cex=1.3 )
mtext( side=1, text="Julian day", outer=TRUE, line=1, cex=1.3 )
}
if( t %in% c(16,rpt$nT) )
{
dev.off()
i <- i + 1
}
}
}
plotArrival(rpt=rpt,folder=folder)
plotArrivalByYear(rpt=rpt,folder=folder)
plotCompResid(rpt=rpt,folder=folder)
plotCompFits(rpt=rpt,folder=folder)
if( saveRun )
{
plotAll(rpt=rpt,folder=folder)
save( rpt, file=paste(folder,"/rpt.Rdata",sep="") )
system( paste("cp ",ctlFile," ",folder,"/estControlFile.txt",sep="") )
}
# Initialize
source(here("analysis/R/run-reconstructions/initRR.R"))
# -- aggregate run-size counts by day, N_gyd --
counts <- read.csv(here("analysis/data/raw/borderCounts.csv"))
# -- GSI sub-stock sampling by day, n_sgyd --
gsi <- read.csv(here("analysis/data/raw/border-gsi-table.csv")) %>%
rename( sample_num=fish )
stockID <- read.csv(here("analysis/data/raw/stockIDs.csv")) %>% arrange(plotOrder)
stockID <- read.csv(here("analysis/data/raw/stockIDs.csv")) %>% arrange(plotOrder)
# External run size indices for fish wheel years only (<2005)
borderPass <- read.csv(here("analysis/data/raw/border-passage.csv"))
source(here("analysis/R/run-reconstructions/procData.R"))
processData()
rpt <- fitRR()
dyn.unload(dynlib(here("analysis/R/run-reconstructions/yukonChinookRunRecon")))          # unlink the C++ code if already linked
source(here("analysis/R/run-reconstructions/initRR.R"))
rpt <- fitRR()
# process and save time-series of spawner abundance
cdn_harvest <- read.csv(here("analysis/data/raw/YkCk_Harvest_CA_Data.csv")) %>%
filter(Type == "CA_Mainstem",
Year > 1984) %>%
select(Year, Estimate)
border_passage <- rpt[["runSize_t"]]
cdn_er <- cdn_harvest$Estimate/(cdn_harvest$Estimate+border_passage)
CU_border_passage <- exp(rpt$lnRunSize_st)*1e-3
CU_spwn <- CU_border_passage * (1-cdn_er)
colnames(CU_spwn) <- seq(1985,2023)
rownames(CU_spwn) <- c("NorthernYukonR.andtribs.","Whiteandtribs.","Pelly","Stewart","Nordenskiold","YukonR.Teslinheadwaters","MiddleYukonR.andtribs.","UpperYukonR.")
CU_spwn_df <- as.data.frame(CU_spwn)
CU_spwn_df$CU <- rownames(CU_spwn)
CU_spawn_long <- CU_spwn_df %>%
pivot_longer(!CU, names_to = 'Year', values_to = 'spawn')
Rse <- filter(rpt$sdrpt,par=="runSize_st")
library(tidyverse)
CU_spawn_long <- CU_spwn_df %>%
pivot_longer(!CU, names_to = 'Year', values_to = 'spawn')
Rse <- filter(rpt$sdrpt,par=="runSize_st")
CU_spawn_long$lwr <- Rse$lCI*1e-3
CU_spawn_long$upr <- Rse$uCI*1e-3
CU_spawn_long$se <- Rse$se*1e-3
mssr_spwn <- CU_spawn_long %>%
mutate(year = as.numeric(Year),
cv = se/spawn,
stock = CU,
mean = as.numeric(spawn)*1000,
obs = 1) %>%
select(stock, year, mean, se, cv, obs)
write.csv(mssr_spwn, here("analysis/data/raw/esc-data.csv"),row.names = F)
mssr_spwn
# calculate CU specific harvest based on reconstructed spawner abundance and aggregate exploitation rate
er <- read.csv(here("analysis/data/raw/rr-table.csv"))
cdn_er <- er %>%
filter(stock == "Canadian",
Year > 1984) %>%
mutate(er = Harvest.rate..../100)
cdn_er
agg_er <- as.vector(cdn_er$er)
agg_er
rep(agg_er,2)
agg_er <- rep(as.vector(cdn_er$er),8)
agg_er
harv <- cbind(mssr_spwn, agg_er)
harv
harv$harv <- (harv$spawn/(1-harv$agg_er))*harv$agg_er
harv$harv <- (harv$mean/(1-harv$agg_er))*harv$agg_er
harv
er
# calculate CU specific harvest based on reconstructed spawner abundance and aggregate exploitation rate
er <- read.csv(here("analysis/data/raw/rr-table.csv"))
cdn_er <- er %>%
filter(stock == "Canadian",
Year > 1984) %>%
mutate(er = Harvest.rate..../100,
cv = Harvest.CV)
cdn_er
er <- read.csv(here("analysis/data/raw/rr-table.csv"))
cdn_er <- er %>%
filter(stock == "Canadian",
Year > 1984) %>%
mutate(er = Harvest.rate..../100,
cv = Harvest.CV)
agg_er <- rep(as.vector(cdn_er$er),8)
agg_cv <- rep(as.vector(cdn_er$cv),8)
harv <- cbind(mssr_spwn, agg_eragg_cv)
harv <- cbind(mssr_spwn, agg_er,agg_cv)
harv$harv <- (harv$mean/(1-harv$agg_er))*harv$agg_er
harv
harvest <- harv[,c(1,2,9,8)]
harvest
colnames(harvest) <- c("population", "year","harv","cv")
harvest
write.csv(harvest,here("analysis/data/raw/harvest-data.csv"))
write.csv(harvest,here("analysis/data/raw/harvest-data.csv"))

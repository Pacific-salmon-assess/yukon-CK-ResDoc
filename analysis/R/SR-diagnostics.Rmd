---
title: "Supplement: Spawner-recruit model diagnostics"
author: "Authors"
output: 
  html_document:
    collapsed: no
    fig_caption: no
    number_sections: no
    smooth_scroll: yes
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(here)
library(tidyverse)
library(ggplotify) #for as.ggplot() to help mcmc_combo() plotting
library(rstan)
library(bayesplot)
library(kableExtra)
source(here("analysis/R/data_functions.R"))

# read in model fits ---------------------------------------------------------------------
AR1.fits <- lapply(list.files(here("analysis/data/generated/model_fits/AR1"),
                              full.names = T), 
                   readRDS)
names(AR1.fits) <- unique(sp_har$CU)[order(unique(sp_har$CU))]

TVA.fits <- lapply(list.files(here("analysis/data/generated/model_fits/TVA"), 
                              full.names = T), 
                   readRDS)
names(TVA.fits) <- unique(sp_har$CU)[order(unique(sp_har$CU))]
```


This document describes fits from both state-space Ricker spawner-recruit models used fit in the Research Document (**link once published online**):

**citation**

Two state-space spawner-recruit models were fit in this paper that serve different purposes. 
First, a Ricker model with autoregressive (AR1) recruitment residuals was fit to estimate biological benchmarks ($S_{gen}$, $S_{MSY}$, and $U_{MSY}$), then a model with time-varying productivity (Ricker $\alpha$ parameter) was fit in order to condition the biological submodel on recent population dynamics in the closed-loop forward simulation. 
These models were fit to each of the 9 CUs one by one, yielding 18 models to diagnose total. 
Data and code to reproduce the analysis and report is available in this [GitHub repository](https://github.com/Pacific-salmon-assess/yukon-CK-ResDoc/tree/main), where you can see the [R code](https://github.com/Pacific-salmon-assess/yukon-CK-ResDoc/blob/main/analysis/R/SR_fit.R) to run the models, and the [models](https://github.com/Pacific-salmon-assess/yukon-CK-ResDoc/tree/main/analysis/Stan) themselves. 


# Diagnostics  

We fit the spawner-recruitment model in a Bayesian estimation framework with Stan [@carpenter_stan_2017; @standevelopmentteamRstanInterfaceStan2023], which implements the No-U-Turn Hamiltonian Markov chain Monte Carlo algorithm [@hoffman2014] for Bayesian statistical inference to generate a joint posterior probability distribution of all unknowns in the model. 
We sampled from 4 chains with **2,000** iterations each and discarded the first half as warm-up. 
We assessed chain convergence visually via trace plots and by ensuring that $\hat{R}$ (potential scale reduction factor; @vehtari2021rank) was less than 1.01 and that the effective sample size was greater than 400. Posterior predictive checks were used to make sure the model returned known values, by simulating new datasets and checking how similar they were to our observed data.    

## Trace plots  
These should be clearly mixed, with no single distribution deviating from others (left column), and no chains exploring a strange space for a few iterations (right column).  


```{r diagnostics, results = 'asis'}
# describe diagnostics in loop -----------------------------------------------------------
min_ESS_AR1 <- NULL
max_Rhat_AR1 <- NULL
min_ESS_TVA <- NULL
max_Rhat_TVA <- NULL

for(i in unique(sp_har$CU)){
  sub_dat <- filter(sp_har, CU==i)
  cat('\n')
  cat("### ", i, "\n") #escape loop and print CU name
  #diagnostics associated w/ AR1 model---
  sub_AR1_summary <- as.data.frame(rstan::summary(AR1.fits[[i]])$summary)
  
  sub_AR1_pars <- rstan::extract(AR1.fits[[i]])
  
  min_ESS_AR1 <- rbind(min_ESS_AR1, data.frame(CU=i, 
                                       ESS=round(min(sub_AR1_summary$n_eff, na.rm=T))))
  
  max_Rhat_AR1 <- rbind(max_Rhat_AR1, data.frame(CU=i, 
                                         Rhat=round(max(sub_AR1_summary$Rhat, na.rm=T), 3)))
  
  R <- (sub_dat$harv+sub_dat$spwn)
  R_rep <- sub_AR1_pars$H_rep[1:500,] + sub_AR1_pars$S_rep[1:500,]
  
  p <- ppc_dens_overlay(R, R_rep) +
    xlim(NA, quantile(R_rep, 0.99)) +
    theme(legend.position = "none") +
    labs(y = "density", x = "y_est", title = "AR1 posterior predictive check")
  print(p)
  
  p <- mcmc_combo(AR1.fits[[i]], pars = c("beta", "lnalpha", "sigma_R", "phi"),
             combo = c("dens_overlay", "trace"),
             gg_theme = legend_none()) |>
    as.ggplot() + 
    labs(title = "AR1 leading parameters")
  print(p)

  p <- mcmc_combo(AR1.fits[[i]], pars = c("D_scale", "D_sum"),
             combo = c("dens_overlay", "trace"),
             gg_theme = legend_none())|> 
    as.ggplot() +
    labs(title = "AR1 age pars")
    print(p)

  p <- mcmc_combo(AR1.fits[[i]], pars = c("Dir_alpha[1]", "Dir_alpha[2]", 
                               "Dir_alpha[3]", "Dir_alpha[4]"),
             combo = c("dens_overlay", "trace"),
             gg_theme = legend_none())|> 
    as.ggplot() +
    labs(title = "AR1 age probs")
    print(p)

  #diagnostics associated w/ TVA model---
  sub_TVA_summary <- as.data.frame(rstan::summary(TVA.fits[[i]])$summary)
  
  sub_TVA_pars <- rstan::extract(TVA.fits[[i]])
  
  min_ESS_TVA <- rbind(min_ESS_TVA, data.frame(CU=i, 
                                               ESS=round(min(sub_TVA_summary$n_eff, na.rm=T))))
  
  max_Rhat_TVA <- rbind(max_Rhat_TVA, data.frame(CU=i, 
                                                 Rhat=round(max(sub_TVA_summary$Rhat, na.rm=T), 3)))
  
  R <- (sub_dat$harv+sub_dat$spwn)
  R_rep <- sub_TVA_pars$H_rep[1:500,] + sub_TVA_pars$S_rep[1:500,]
  
  p <- ppc_dens_overlay(R, R_rep) +
    xlim(NA, quantile(R_rep, 0.99)) +
    theme(legend.position = "none") +
    labs(y = "density", x = "y_est", title = "TV posterior predictive check")
  
  p <- mcmc_combo(TVA.fits[[i]], pars = c("ln_alpha0", "beta", "F_rw", "mean_ln_R0"), 
                  combo = c("dens_overlay", "trace"),
                  gg_theme = legend_none()) |> 
    as.ggplot() +
    labs(title =  "TV leading parameters")
    print(p)
    
  p <- mcmc_combo(TVA.fits[[i]], pars = c("sigma_alpha", "sigma_R", "sigma_tot"), 
                  combo = c("dens_overlay", "trace"),
                  gg_theme = legend_none()) |> 
    as.ggplot() +
    labs(title =  "TV variance components")
    print(p)

  p <- mcmc_combo(TVA.fits[[i]], pars = c("D_scale", "D_sum"),
                  combo = c("dens_overlay", "trace"),
                  gg_theme = legend_none())|> 
    as.ggplot() +
    labs(title = "TV age pars")
    print(p)

  p <- mcmc_combo(TVA.fits[[i]], pars = c("Dir_alpha[1]", "Dir_alpha[2]", 
                                          "Dir_alpha[3]", "Dir_alpha[4]"),
                  combo = c("dens_overlay", "trace"),
                  gg_theme = legend_none())|> 
    as.ggplot() +
    labs(title = "TV age probs")
    print(p)
  cat('\n')
}
```

## ESS and $\hat{R}$  

We hope minimum effective sample sizes are greater than ***2000*** and that $\hat{R}$ are less than 1.05.  

For the AR1 model:  
```{r AR1-diag}
AR1.diag <- left_join(min_ESS_AR1, max_Rhat_AR1, by = "CU")
kable(AR1.diag)
```

and the time varying model:  
```{r TV-diag}
TVA.diag <- left_join(min_ESS_TVA, max_Rhat_TVA, by = "CU")
kable(TVA.diag)
```

We see some problems with the time varying model, and have explored various parametrizations and options to include [semi-informative beta priors](https://github.com/Pacific-salmon-assess/yukon-CK-ResDoc/tree/main/analysis/Stan/semi_inform) that did not improve diagnostics. We imagine these issues in the time-varying model are due to the extreme, pronounced decline in productivity, and the correlation between productivity and the stationary capacity prior (i.e., Ricker $\beta$). 

**add a head(max(Rhat)) type thing to show what model*parms had problems?**